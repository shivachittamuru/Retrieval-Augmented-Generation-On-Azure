{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "loader = UnstructuredFileLoader(\"state_of_the_union.txt\")\n",
    "raw_documents = loader.load()\n",
    "len(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split text\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.api_base = os.environ['OPENAI_API_BASE']\n",
    "openai.api_type = os.environ['OPENAI_API_TYPE']\n",
    "openai.api_version = \"2023-06-01-preview\" # # this version is required for annotations\n",
    "\n",
    "model = os.environ['CHAT_MODEL_NAME']\n",
    "embedding_model = os.environ['EMBEDDING_MODEL_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data to vectorstore\n",
    "embeddings = OpenAIEmbeddings(chunk_size=1)\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vectorstore\n",
    "with open(\"vectorstore.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorstore, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chain(vectorstore):\n",
    "    chat = AzureChatOpenAI(temperature=0,\n",
    "        max_tokens=500,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_version=openai.api_version,\n",
    "        deployment_name=model,\n",
    "        openai_api_key=openai.api_key,\n",
    "        openai_api_type = openai.api_type    \n",
    "    )\n",
    "\n",
    "    retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "\n",
    "    from langchain.memory import ConversationBufferMemory\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=chat,\n",
    "        retriever=retriever,\n",
    "        memory=memory,\n",
    "        chain_type=\"stuff\"\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "def ask_with_memory(vectorstore, question, chat_history=[]):\n",
    "    chat = AzureChatOpenAI(temperature=0,\n",
    "        max_tokens=500,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_version=openai.api_version,\n",
    "        deployment_name=model,\n",
    "        openai_api_key=openai.api_key,\n",
    "        openai_api_type = openai.api_type    \n",
    "    )\n",
    "\n",
    "    retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "\n",
    "    # from langchain.memory import ConversationBufferMemory\n",
    "    # memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=chat,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    result = qa_chain({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result[\"answer\"]))\n",
    "    return result, chat_history\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat with your docs!\n",
      "Human:\n",
      "Hello, how many sanctions were imposed on Russia?\n",
      "AI:\n",
      "The context does not provide a specific number of sanctions imposed on Russia. However, it does mention that the United States and its allies are enforcing powerful economic sanctions on Russia, cutting off its largest banks from the international financial system, preventing its central bank from defending the Russian Ruble, and choking off its access to technology. Additionally, the U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs, and the U.S. and its European allies are finding and seizing their ill-begotten gains.\n",
      "Human:\n",
      "What did President say about Ketanji Brown Jackson?\n",
      "AI:\n",
      "The United States and its allies are enforcing powerful economic sanctions on Russia. They are cutting off Russia’s largest banks from the international financial system, preventing Russia’s central bank from defending the Russian Ruble, and choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come. The U.S. Department of Justice is also assembling a dedicated task force to go after the crimes of Russian oligarchs. Additionally, the United States and its European allies are joining forces to find and seize the ill-begotten gains of Russian oligarchs, including their yachts, luxury apartments, and private jets.\n"
     ]
    }
   ],
   "source": [
    "qa_chain = get_chain(vectorstore)\n",
    "chat_history = []\n",
    "print(\"Chat with your docs!\")\n",
    "while True:\n",
    "    question = input()\n",
    "    if question in [\"quit\", \"exit\"]:\n",
    "        break\n",
    "    result = qa_chain({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result[\"answer\"]))\n",
    "    print(\"Human:\")\n",
    "    print(question)\n",
    "    print(\"AI:\")\n",
    "    print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat with your docs!\n",
      "User:\n",
      "My name is Shiva! what is your name?\n",
      "AI:\n",
      "I'm an AI language model created by OpenAI. I don't have a name, but you can call me OpenAI. How can I assist you today, Shiva?\n",
      "User:\n",
      "What did the president say about Ketanji Brown Jackson?\n",
      "AI:\n",
      "The President nominated Circuit Court of Appeals Judge Ketanji Brown Jackson and mentioned that she is one of the nation's top legal minds, a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers.\n",
      "User:\n",
      "How many sanctions were imposed on Russia?\n",
      "AI:\n",
      "The context does not provide a specific number of sanctions imposed on Russia. However, it mentions that the United States and its allies are enforcing powerful economic sanctions, cutting off Russia's largest banks from the international financial system, preventing Russia's central bank from defending the Russian Ruble, and choking off Russia's access to technology that will sap its economic strength and weaken its military for years to come.\n",
      "User:\n",
      "What is my name?\n",
      "AI:\n",
      "I am an AI language model created by OpenAI. You can call me OpenAI. How can I assist you today?\n",
      "User:\n",
      "I wasn't asking for you name. Could you remind me my name?\n",
      "AI:\n",
      "I'm sorry, but I don't have access to your name as we are communicating through a text interface.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "print(\"Chat with your docs!\")\n",
    "while True:\n",
    "    question = input()\n",
    "    if question in [\"quit\", \"exit\"]:\n",
    "        break\n",
    "    result, chat_history = ask_with_memory(vectorstore, question, chat_history)\n",
    "    chat_history.append((question, result[\"answer\"]))\n",
    "    print(\"User:\")\n",
    "    print(question)\n",
    "    print(\"AI:\")\n",
    "    print(result[\"answer\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aoai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
