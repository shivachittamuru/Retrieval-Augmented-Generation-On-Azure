{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "640e4bbc",
   "metadata": {},
   "source": [
    "# Project: Question-Answering on Private Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b748fd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f13727cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pypdf -q\n",
    "# pip install docx2txt -q\n",
    "# pip install wikipedia -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4bdf053",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.api_base = os.environ['OPENAI_API_BASE']\n",
    "openai.api_type = os.environ['OPENAI_API_TYPE']\n",
    "openai.api_version = \"2023-06-01-preview\" # # this version is required for annotations\n",
    "\n",
    "model = os.environ['CHAT_MODEL_NAME']\n",
    "embedding_model = os.environ['EMBEDDING_MODEL_NAME']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07900179",
   "metadata": {},
   "source": [
    "### Loading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ae19b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file):\n",
    "    import os\n",
    "    name, extension = os.path.splitext(file)\n",
    "\n",
    "    \n",
    "    if extension == '.pdf':\n",
    "        from langchain.document_loaders import PyPDFLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension == '.docx':\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = Docx2txtLoader(file)\n",
    "    else:\n",
    "        print('Document format is not supported!')\n",
    "        return None\n",
    "\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "\n",
    "# wikipedia\n",
    "def load_from_wikipedia(query, lang='en', load_max_docs=2):\n",
    "    from langchain.document_loaders import WikipediaLoader\n",
    "    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    return data\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "367bb8ad",
   "metadata": {},
   "source": [
    "### Chunking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c3cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b298177",
   "metadata": {},
   "source": [
    "### Calculating Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add191c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total Tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens / 1000 * 0.0004:.6f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27f92afa",
   "metadata": {},
   "source": [
    "### Embedding and Uploading to a Vector Database (Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c72c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings(index_name, chunks):\n",
    "    import pinecone\n",
    "    from langchain.vectorstores import Pinecone\n",
    "    from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(chunk_size=1)\n",
    "    \n",
    "    pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))\n",
    "    \n",
    "    if index_name in pinecone.list_indexes():\n",
    "        print(f'Index {index_name} already exists. Loading embeddings ... ', end='')\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Creating index {index_name} and embeddings ...', end='')\n",
    "        pinecone.create_index(index_name, dimension=1536, metric='cosine')\n",
    "        vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print('Ok')\n",
    "        \n",
    "    return vector_store\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52ef1091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name='all'):\n",
    "    import pinecone\n",
    "    pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))\n",
    "    \n",
    "    if index_name == 'all':\n",
    "        indexes = pinecone.list_indexes()\n",
    "        print('Deleting all indexes ... ')\n",
    "        for index in indexes:\n",
    "            pinecone.delete_index(index)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Deleting index {index_name} ...', end='')\n",
    "        pinecone.delete_index(index_name)\n",
    "        print('Ok')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "462a94cb",
   "metadata": {},
   "source": [
    "### Asking and Getting Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08b0a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_without_memory(vector_store, q):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "    chat = AzureChatOpenAI(temperature=0,\n",
    "        max_tokens=500,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_version=openai.api_version,\n",
    "        deployment_name=model,\n",
    "        openai_api_key=openai.api_key,\n",
    "        openai_api_type = openai.api_type    \n",
    "    )\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(llm=chat, chain_type=\"stuff\", retriever=retriever)\n",
    "    \n",
    "    answer = chain.run(q)\n",
    "    return answer\n",
    "    \n",
    "    \n",
    "def ask_with_memory(vector_store, question, chat_history=[]):\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain.chat_models import AzureChatOpenAI\n",
    "    \n",
    "    chat = AzureChatOpenAI(temperature=0,\n",
    "        max_tokens=500,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_version=openai.api_version,\n",
    "        deployment_name=model,\n",
    "        openai_api_key=openai.api_key,\n",
    "        openai_api_type = openai.api_type    \n",
    "    )\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "    \n",
    "    crc = ConversationalRetrievalChain.from_llm(chat, retriever)\n",
    "    result = crc({'question': question, 'chat_history': chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    \n",
    "    return result, chat_history\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1efe8fc",
   "metadata": {},
   "source": [
    "### Running Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23fd7147",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files/us_constitution.pdf\n",
      "You have 41 pages in your data\n",
      "There are 1137 characters in the page\n"
     ]
    }
   ],
   "source": [
    "data = load_document('files/us_constitution.pdf')\n",
    "# print(data[1].page_content)\n",
    "# print(data[10].metadata)\n",
    "\n",
    "print(f'You have {len(data)} pages in your data')\n",
    "print(f'There are {len(data[20].page_content)} characters in the page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d11b7652",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files/the_great_gatsby.docx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = load_document('files/the_great_gatsby.docx')\n",
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6054462e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = load_from_wikipedia('GPT-4')\n",
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64b5d7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_data(data)\n",
    "print(len(chunks))\n",
    "# print(chunks[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faa75175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 16711\n",
      "Embedding Cost in USD: 0.006684\n"
     ]
    }
   ],
   "source": [
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f4f798d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes ... \n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8525a620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index askadocument and embeddings ...Ok\n"
     ]
    }
   ],
   "source": [
    "index_name = 'askadocument'\n",
    "vector_store = insert_or_fetch_embeddings(index_name, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b158ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are currently 27 amendments in the US Constitution.\n"
     ]
    }
   ],
   "source": [
    "q = 'How many amendments are in the US constitution?'\n",
    "answer = ask_without_memory(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64a8cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are currently 27 amendments in the US Constitution.\n",
      "\n",
      "Chat History: [('How many amendments are in the US constitution?', 'There are currently 27 amendments in the US Constitution.')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "question = 'How many amendments are in the US constitution?'\n",
    "result, chat_history = ask_with_memory(vector_store, question, chat_history=chat_history)\n",
    "print(result['answer'])\n",
    "print(f\"\\nChat History: {chat_history}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8aab7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of multiplying the number of amendments in the US Constitution by 2 is not provided in the given context. The US Constitution has 27 amendments, but there is no information on multiplying it by 2.\n",
      "[('How many amendments are in the US constitution?', 'There are currently 27 amendments in the US Constitution.'), ('Multiply that number by 2', 'The result of multiplying the number of amendments in the US Constitution by 2 is not provided in the given context. The US Constitution has 27 amendments, but there is no information on multiplying it by 2.')]\n"
     ]
    }
   ],
   "source": [
    "question = 'Multiply that number by 2'\n",
    "result, chat_history = ask_with_memory(vector_store, question, chat_history=chat_history)\n",
    "print(result['answer'])\n",
    "print(f\"\\nChat History: {chat_history}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25388ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "i = 1\n",
    "print('Write Quit or Exit to quit.')\n",
    "while True:\n",
    "    q = input(f'Question #{i}: ')\n",
    "    i = i + 1\n",
    "    if q.lower() in ['quit', 'exit']:\n",
    "        print('Quitting ... bye bye!')\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    \n",
    "    answer = ask_without_memory(vector_store, q)\n",
    "    print(f'\\nAnswer: {answer}')\n",
    "    print(f'\\n {\"-\" * 50} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d19c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "i = 1\n",
    "chat_history = []\n",
    "print('Write Quit or Exit to quit.')\n",
    "while True:\n",
    "    q = input(f'Question #{i}: ')\n",
    "    i = i + 1\n",
    "    if q.lower() in ['quit', 'exit']:\n",
    "        print('Quitting ... bye bye!')\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    \n",
    "    answer, chat_history = ask_with_memory(vector_store, q, chat_history=chat_history)\n",
    "    print(f'\\nAnswer: {answer}')\n",
    "    print(f'\\n {\"-\" * 50} \\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
